{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94550cc-2505-46a6-acc1-e5356d4c2b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 requests pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73c7f7c-3bc0-4ab8-a33a-4da02327d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_reddit(keyword=\"crime\", subreddit=\"artificial\", max_posts=200):\n",
    "    posts = []\n",
    "    after = None\n",
    "\n",
    "    while len(posts) < max_posts:\n",
    "        url = f\"https://www.reddit.com/r/{subreddit}/search.json?q={keyword}&restrict_sr=1&sort=new&limit=100\"\n",
    "        if after:\n",
    "            url += f\"&after={after}\"\n",
    "        \n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        res = requests.get(url, headers=headers)\n",
    "        data = res.json()\n",
    "\n",
    "        children = data[\"data\"][\"children\"]\n",
    "        if not children:\n",
    "            break\n",
    "\n",
    "        for child in children:\n",
    "            post = child[\"data\"]\n",
    "            title = post.get(\"title\", \"\")\n",
    "            selftext = post.get(\"selftext\", \"\")\n",
    "            url = \"https://reddit.com\" + post.get(\"permalink\", \"\")\n",
    "            content = selftext if selftext else title\n",
    "\n",
    "            posts.append({\"title\": title, \"url\": url, \"content\": content})\n",
    "\n",
    "        after = data[\"data\"].get(\"after\")\n",
    "        if not after:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(posts[:max_posts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256d2291-74e6-4d73-924c-d99349f34d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles after combining and filtering: 139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-Minute Daily AI News 2/22/2025</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1iw2y...</td>\n",
       "      <td>1. **Googleâ€™s**Â â€˜Career Dreamerâ€™ uses AI to he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dawn of The New Age (Antichrist Unveiled)</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1ioaj...</td>\n",
       "      <td>**These short stories are about Biblically rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-Minute Daily AI News 2/1/2025</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1ifq2...</td>\n",
       "      <td>1. UK makes use of AI tools to create child ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Teen victim of graphic deepfake pornography wo...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1hd0m...</td>\n",
       "      <td>Teen victim of graphic deepfake pornography wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China Unveils Sci-Fi Inspired Spherical AI Pol...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1hcg2...</td>\n",
       "      <td>China Unveils Sci-Fi Inspired Spherical AI Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>iâ€™ve done 10+ hours of searching but canâ€™t fin...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/121os...</td>\n",
       "      <td>i want to make a childrenâ€™s book for my nieces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Question: is it possible to create such illust...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/11uy7...</td>\n",
       "      <td>Question: is it possible to create such illust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Discord will use AI functions. Yes or Ney?</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/11nqx...</td>\n",
       "      <td>Reference: https://www.tech360.tv/discord-roll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Do you think AI purposefully \"nerfs\" some ques...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/11hjq...</td>\n",
       "      <td>Do you think AI purposefully \"nerfs\" some ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>AI program creates police sketches. Experts sa...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/110ir...</td>\n",
       "      <td>AI program creates police sketches. Experts sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                   One-Minute Daily AI News 2/22/2025   \n",
       "1        The Dawn of The New Age (Antichrist Unveiled)   \n",
       "2                    One-Minute Daily AI News 2/1/2025   \n",
       "3    Teen victim of graphic deepfake pornography wo...   \n",
       "4    China Unveils Sci-Fi Inspired Spherical AI Pol...   \n",
       "..                                                 ...   \n",
       "96   iâ€™ve done 10+ hours of searching but canâ€™t fin...   \n",
       "97   Question: is it possible to create such illust...   \n",
       "98          Discord will use AI functions. Yes or Ney?   \n",
       "99   Do you think AI purposefully \"nerfs\" some ques...   \n",
       "100  AI program creates police sketches. Experts sa...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://reddit.com/r/artificial/comments/1iw2y...   \n",
       "1    https://reddit.com/r/artificial/comments/1ioaj...   \n",
       "2    https://reddit.com/r/artificial/comments/1ifq2...   \n",
       "3    https://reddit.com/r/artificial/comments/1hd0m...   \n",
       "4    https://reddit.com/r/artificial/comments/1hcg2...   \n",
       "..                                                 ...   \n",
       "96   https://reddit.com/r/artificial/comments/121os...   \n",
       "97   https://reddit.com/r/artificial/comments/11uy7...   \n",
       "98   https://reddit.com/r/artificial/comments/11nqx...   \n",
       "99   https://reddit.com/r/artificial/comments/11hjq...   \n",
       "100  https://reddit.com/r/artificial/comments/110ir...   \n",
       "\n",
       "                                               content  \n",
       "0    1. **Googleâ€™s**Â â€˜Career Dreamerâ€™ uses AI to he...  \n",
       "1    **These short stories are about Biblically rel...  \n",
       "2    1. UK makes use of AI tools to create child ab...  \n",
       "3    Teen victim of graphic deepfake pornography wo...  \n",
       "4    China Unveils Sci-Fi Inspired Spherical AI Pol...  \n",
       "..                                                 ...  \n",
       "96   i want to make a childrenâ€™s book for my nieces...  \n",
       "97   Question: is it possible to create such illust...  \n",
       "98   Reference: https://www.tech360.tv/discord-roll...  \n",
       "99   Do you think AI purposefully \"nerfs\" some ques...  \n",
       "100  AI program creates police sketches. Experts sa...  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape 67+ articles on \"crime\"\n",
    "df_crime = scrape_reddit(keyword=\"crime\")\n",
    "df_crime.drop_duplicates(subset=\"url\", inplace=True)\n",
    "df_crime = df_crime[df_crime[\"content\"].str.len() > 30]\n",
    "\n",
    "# Scrape more with \"police\"\n",
    "df_police = scrape_reddit(keyword=\"police\")\n",
    "df_police.drop_duplicates(subset=\"url\", inplace=True)\n",
    "df_police = df_police[df_police[\"content\"].str.len() > 30]\n",
    "\n",
    "# Combine\n",
    "df_combined = pd.concat([df_crime, df_police]).drop_duplicates(subset=\"url\").reset_index(drop=True)\n",
    "\n",
    "print(f\"Total articles after combining and filtering: {len(df_combined)}\")\n",
    "df_combined.head(101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141860a8-9fd7-46b6-a959-9dc29e5e3e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(prompt, model=\"mistral\"):  # changed llama3 â†’ mistral\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    return response.json()[\"response\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3a89653-752c-4a94-aeba-bae9682dd5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš™ï¸ Running batch 1 to 10\n",
      "ğŸ” Analyzing post 1/139...\n",
      "âœ… Done in 57.53 sec\n",
      "ğŸ” Analyzing post 2/139...\n",
      "âœ… Done in 42.97 sec\n",
      "ğŸ” Analyzing post 3/139...\n",
      "âœ… Done in 35.83 sec\n",
      "ğŸ” Analyzing post 4/139...\n",
      "âœ… Done in 34.33 sec\n",
      "ğŸ” Analyzing post 5/139...\n",
      "âœ… Done in 28.16 sec\n",
      "ğŸ” Analyzing post 6/139...\n",
      "âœ… Done in 21.67 sec\n",
      "ğŸ” Analyzing post 7/139...\n",
      "âœ… Done in 33.39 sec\n",
      "ğŸ” Analyzing post 8/139...\n",
      "âœ… Done in 34.8 sec\n",
      "ğŸ” Analyzing post 9/139...\n",
      "âœ… Done in 27.59 sec\n",
      "ğŸ” Analyzing post 10/139...\n",
      "âœ… Done in 45.64 sec\n",
      "\n",
      "âš™ï¸ Running batch 11 to 20\n",
      "ğŸ” Analyzing post 21/139...\n",
      "âœ… Done in 24.91 sec\n",
      "ğŸ” Analyzing post 22/139...\n",
      "âœ… Done in 43.38 sec\n",
      "ğŸ” Analyzing post 23/139...\n",
      "âœ… Done in 30.32 sec\n",
      "ğŸ” Analyzing post 24/139...\n",
      "âœ… Done in 38.55 sec\n",
      "ğŸ” Analyzing post 25/139...\n",
      "âœ… Done in 40.15 sec\n",
      "ğŸ” Analyzing post 26/139...\n",
      "âœ… Done in 44.36 sec\n",
      "ğŸ” Analyzing post 27/139...\n",
      "âœ… Done in 62.84 sec\n",
      "ğŸ” Analyzing post 28/139...\n",
      "âœ… Done in 35.21 sec\n",
      "ğŸ” Analyzing post 29/139...\n",
      "âœ… Done in 33.4 sec\n",
      "ğŸ” Analyzing post 30/139...\n",
      "âœ… Done in 31.54 sec\n",
      "\n",
      "âš™ï¸ Running batch 21 to 30\n",
      "ğŸ” Analyzing post 41/139...\n",
      "âœ… Done in 20.03 sec\n",
      "ğŸ” Analyzing post 42/139...\n",
      "âœ… Done in 26.07 sec\n",
      "ğŸ” Analyzing post 43/139...\n",
      "âœ… Done in 34.66 sec\n",
      "ğŸ” Analyzing post 44/139...\n",
      "âœ… Done in 29.76 sec\n",
      "ğŸ” Analyzing post 45/139...\n",
      "âœ… Done in 38.12 sec\n",
      "ğŸ” Analyzing post 46/139...\n",
      "âœ… Done in 34.24 sec\n",
      "ğŸ” Analyzing post 47/139...\n",
      "âœ… Done in 22.19 sec\n",
      "ğŸ” Analyzing post 48/139...\n",
      "âœ… Done in 31.63 sec\n",
      "ğŸ” Analyzing post 49/139...\n",
      "âœ… Done in 34.01 sec\n",
      "ğŸ” Analyzing post 50/139...\n",
      "âœ… Done in 29.52 sec\n",
      "\n",
      "âš™ï¸ Running batch 31 to 40\n",
      "ğŸ” Analyzing post 61/139...\n",
      "âœ… Done in 34.13 sec\n",
      "ğŸ” Analyzing post 62/139...\n",
      "âœ… Done in 13.95 sec\n",
      "ğŸ” Analyzing post 63/139...\n",
      "âœ… Done in 58.83 sec\n",
      "ğŸ” Analyzing post 64/139...\n",
      "âœ… Done in 47.73 sec\n",
      "ğŸ” Analyzing post 65/139...\n",
      "âœ… Done in 19.52 sec\n",
      "ğŸ” Analyzing post 66/139...\n",
      "âœ… Done in 58.33 sec\n",
      "ğŸ” Analyzing post 67/139...\n",
      "âœ… Done in 19.15 sec\n",
      "ğŸ” Analyzing post 68/139...\n",
      "âœ… Done in 19.92 sec\n",
      "ğŸ” Analyzing post 69/139...\n",
      "âœ… Done in 39.29 sec\n",
      "ğŸ” Analyzing post 70/139...\n",
      "âœ… Done in 45.82 sec\n",
      "\n",
      "âš™ï¸ Running batch 41 to 50\n",
      "ğŸ” Analyzing post 81/139...\n",
      "âœ… Done in 42.8 sec\n",
      "ğŸ” Analyzing post 82/139...\n",
      "âœ… Done in 43.13 sec\n",
      "ğŸ” Analyzing post 83/139...\n",
      "âœ… Done in 28.81 sec\n",
      "ğŸ” Analyzing post 84/139...\n",
      "âœ… Done in 14.8 sec\n",
      "ğŸ” Analyzing post 85/139...\n",
      "âœ… Done in 22.17 sec\n",
      "ğŸ” Analyzing post 86/139...\n",
      "âœ… Done in 27.68 sec\n",
      "ğŸ” Analyzing post 87/139...\n",
      "âœ… Done in 19.57 sec\n",
      "ğŸ” Analyzing post 88/139...\n",
      "âœ… Done in 35.22 sec\n",
      "ğŸ” Analyzing post 89/139...\n",
      "âœ… Done in 25.76 sec\n",
      "ğŸ” Analyzing post 90/139...\n",
      "âœ… Done in 21.88 sec\n",
      "\n",
      "âš™ï¸ Running batch 51 to 60\n",
      "ğŸ” Analyzing post 101/139...\n",
      "âœ… Done in 36.35 sec\n",
      "ğŸ” Analyzing post 102/139...\n",
      "âœ… Done in 19.72 sec\n",
      "ğŸ” Analyzing post 103/139...\n",
      "âœ… Done in 26.26 sec\n",
      "ğŸ” Analyzing post 104/139...\n",
      "âœ… Done in 33.12 sec\n",
      "ğŸ” Analyzing post 105/139...\n",
      "âœ… Done in 28.09 sec\n",
      "ğŸ” Analyzing post 106/139...\n",
      "âœ… Done in 37.33 sec\n",
      "ğŸ” Analyzing post 107/139...\n",
      "âœ… Done in 37.02 sec\n",
      "ğŸ” Analyzing post 108/139...\n",
      "âœ… Done in 35.19 sec\n",
      "ğŸ” Analyzing post 109/139...\n",
      "âœ… Done in 23.63 sec\n",
      "ğŸ” Analyzing post 110/139...\n",
      "âœ… Done in 34.8 sec\n",
      "\n",
      "âš™ï¸ Running batch 61 to 70\n",
      "ğŸ” Analyzing post 121/139...\n",
      "âœ… Done in 30.0 sec\n",
      "ğŸ” Analyzing post 122/139...\n",
      "âœ… Done in 30.43 sec\n",
      "ğŸ” Analyzing post 123/139...\n",
      "âœ… Done in 27.15 sec\n",
      "ğŸ” Analyzing post 124/139...\n",
      "âœ… Done in 33.31 sec\n",
      "ğŸ” Analyzing post 125/139...\n",
      "âœ… Done in 35.57 sec\n",
      "ğŸ” Analyzing post 126/139...\n",
      "âœ… Done in 44.91 sec\n",
      "ğŸ” Analyzing post 127/139...\n",
      "âœ… Done in 20.91 sec\n",
      "ğŸ” Analyzing post 128/139...\n",
      "âœ… Done in 44.37 sec\n",
      "ğŸ” Analyzing post 129/139...\n",
      "âœ… Done in 57.82 sec\n",
      "ğŸ” Analyzing post 130/139...\n",
      "âœ… Done in 22.39 sec\n",
      "\n",
      "âš™ï¸ Running batch 71 to 80\n",
      "ğŸ” Analyzing post 141/139...\n",
      "âœ… Done in 51.34 sec\n",
      "ğŸ” Analyzing post 142/139...\n",
      "âœ… Done in 17.55 sec\n",
      "ğŸ” Analyzing post 143/139...\n",
      "âœ… Done in 29.68 sec\n",
      "ğŸ” Analyzing post 144/139...\n",
      "âœ… Done in 28.31 sec\n",
      "ğŸ” Analyzing post 145/139...\n",
      "âœ… Done in 23.19 sec\n",
      "ğŸ” Analyzing post 146/139...\n",
      "âœ… Done in 64.21 sec\n",
      "ğŸ” Analyzing post 147/139...\n",
      "âœ… Done in 51.72 sec\n",
      "ğŸ” Analyzing post 148/139...\n",
      "âœ… Done in 55.88 sec\n",
      "ğŸ” Analyzing post 149/139...\n",
      "âœ… Done in 52.4 sec\n",
      "ğŸ” Analyzing post 150/139...\n",
      "âœ… Done in 48.35 sec\n",
      "\n",
      "âš™ï¸ Running batch 81 to 90\n",
      "ğŸ” Analyzing post 161/139...\n",
      "âœ… Done in 51.81 sec\n",
      "ğŸ” Analyzing post 162/139...\n",
      "âœ… Done in 50.15 sec\n",
      "ğŸ” Analyzing post 163/139...\n",
      "âœ… Done in 36.93 sec\n",
      "ğŸ” Analyzing post 164/139...\n",
      "âœ… Done in 55.96 sec\n",
      "ğŸ” Analyzing post 165/139...\n",
      "âœ… Done in 44.63 sec\n",
      "ğŸ” Analyzing post 166/139...\n",
      "âœ… Done in 37.87 sec\n",
      "ğŸ” Analyzing post 167/139...\n",
      "âœ… Done in 57.52 sec\n",
      "ğŸ” Analyzing post 168/139...\n",
      "âœ… Done in 32.26 sec\n",
      "ğŸ” Analyzing post 169/139...\n",
      "âœ… Done in 36.43 sec\n",
      "ğŸ” Analyzing post 170/139...\n",
      "âœ… Done in 42.35 sec\n",
      "\n",
      "âš™ï¸ Running batch 91 to 100\n",
      "ğŸ” Analyzing post 181/139...\n",
      "âœ… Done in 47.56 sec\n",
      "ğŸ” Analyzing post 182/139...\n",
      "âœ… Done in 63.38 sec\n",
      "ğŸ” Analyzing post 183/139...\n",
      "âœ… Done in 33.35 sec\n",
      "ğŸ” Analyzing post 184/139...\n",
      "âœ… Done in 36.41 sec\n",
      "ğŸ” Analyzing post 185/139...\n",
      "âœ… Done in 45.91 sec\n",
      "ğŸ” Analyzing post 186/139...\n",
      "âœ… Done in 39.43 sec\n",
      "ğŸ” Analyzing post 187/139...\n",
      "âœ… Done in 30.72 sec\n",
      "ğŸ” Analyzing post 188/139...\n",
      "âœ… Done in 40.76 sec\n",
      "ğŸ” Analyzing post 189/139...\n",
      "âœ… Done in 38.6 sec\n",
      "ğŸ” Analyzing post 190/139...\n",
      "âœ… Done in 28.29 sec\n",
      "\n",
      "âš™ï¸ Running batch 101 to 110\n",
      "ğŸ” Analyzing post 201/139...\n",
      "âœ… Done in 20.92 sec\n",
      "ğŸ” Analyzing post 202/139...\n",
      "âœ… Done in 54.33 sec\n",
      "ğŸ” Analyzing post 203/139...\n",
      "âœ… Done in 24.67 sec\n",
      "ğŸ” Analyzing post 204/139...\n",
      "âœ… Done in 16.73 sec\n",
      "ğŸ” Analyzing post 205/139...\n",
      "âœ… Done in 21.11 sec\n",
      "ğŸ” Analyzing post 206/139...\n",
      "âœ… Done in 42.82 sec\n",
      "ğŸ” Analyzing post 207/139...\n",
      "âœ… Done in 23.74 sec\n",
      "ğŸ” Analyzing post 208/139...\n",
      "âœ… Done in 33.6 sec\n",
      "ğŸ” Analyzing post 209/139...\n",
      "âœ… Done in 24.89 sec\n",
      "ğŸ” Analyzing post 210/139...\n",
      "âœ… Done in 17.99 sec\n",
      "\n",
      "âš™ï¸ Running batch 111 to 120\n",
      "ğŸ” Analyzing post 221/139...\n",
      "âœ… Done in 47.56 sec\n",
      "ğŸ” Analyzing post 222/139...\n",
      "âœ… Done in 35.21 sec\n",
      "ğŸ” Analyzing post 223/139...\n",
      "âœ… Done in 51.63 sec\n",
      "ğŸ” Analyzing post 224/139...\n",
      "âœ… Done in 20.81 sec\n",
      "ğŸ” Analyzing post 225/139...\n",
      "âœ… Done in 29.25 sec\n",
      "ğŸ” Analyzing post 226/139...\n",
      "âœ… Done in 37.42 sec\n",
      "ğŸ” Analyzing post 227/139...\n",
      "âœ… Done in 22.89 sec\n",
      "ğŸ” Analyzing post 228/139...\n",
      "âœ… Done in 27.81 sec\n",
      "ğŸ” Analyzing post 229/139...\n",
      "âœ… Done in 22.12 sec\n",
      "ğŸ” Analyzing post 230/139...\n",
      "âœ… Done in 59.07 sec\n",
      "\n",
      "âš™ï¸ Running batch 121 to 130\n",
      "ğŸ” Analyzing post 241/139...\n",
      "âœ… Done in 33.9 sec\n",
      "ğŸ” Analyzing post 242/139...\n",
      "âœ… Done in 22.78 sec\n",
      "ğŸ” Analyzing post 243/139...\n",
      "âœ… Done in 22.98 sec\n",
      "ğŸ” Analyzing post 244/139...\n",
      "âœ… Done in 27.8 sec\n",
      "ğŸ” Analyzing post 245/139...\n",
      "âœ… Done in 27.74 sec\n",
      "ğŸ” Analyzing post 246/139...\n",
      "âœ… Done in 38.19 sec\n",
      "ğŸ” Analyzing post 247/139...\n",
      "âœ… Done in 27.78 sec\n",
      "ğŸ” Analyzing post 248/139...\n",
      "âœ… Done in 27.04 sec\n",
      "ğŸ” Analyzing post 249/139...\n",
      "âœ… Done in 21.51 sec\n",
      "ğŸ” Analyzing post 250/139...\n",
      "âœ… Done in 54.48 sec\n",
      "\n",
      "âš™ï¸ Running batch 131 to 139\n",
      "ğŸ” Analyzing post 261/139...\n",
      "âœ… Done in 18.67 sec\n",
      "ğŸ” Analyzing post 262/139...\n",
      "âœ… Done in 22.19 sec\n",
      "ğŸ” Analyzing post 263/139...\n",
      "âœ… Done in 30.67 sec\n",
      "ğŸ” Analyzing post 264/139...\n",
      "âœ… Done in 32.21 sec\n",
      "ğŸ” Analyzing post 265/139...\n",
      "âœ… Done in 28.93 sec\n",
      "ğŸ” Analyzing post 266/139...\n",
      "âœ… Done in 18.79 sec\n",
      "ğŸ” Analyzing post 267/139...\n",
      "âœ… Done in 36.97 sec\n",
      "ğŸ” Analyzing post 268/139...\n",
      "âœ… Done in 26.53 sec\n",
      "ğŸ” Analyzing post 269/139...\n",
      "âœ… Done in 29.86 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0, len(df_combined), 10):\n",
    "    batch = df_combined.iloc[i:i+10].copy()\n",
    "    print(f\"\\nâš™ï¸ Running batch {i+1} to {i+len(batch)}\")\n",
    "\n",
    "    batch_responses = []\n",
    "    for j, row in batch.iterrows():\n",
    "        print(f\"ğŸ” Analyzing post {i+j+1}/{len(df_combined)}...\")\n",
    "        start = time.time()\n",
    "        response = analyze_article(row[\"content\"])\n",
    "        duration = round(time.time() - start, 2)\n",
    "        print(f\"âœ… Done in {duration} sec\")\n",
    "        batch_responses.append(response)\n",
    "\n",
    "    batch[\"analysis\"] = batch_responses\n",
    "    results.append(batch)\n",
    "\n",
    "    # Save after each batch\n",
    "    pd.concat(results).to_csv(\"ai_crime_analysis_progress.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f987937-d040-4e5f-84d0-33e73de2725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(results).reset_index(drop=True)\n",
    "\n",
    "def parse_analysis(response):\n",
    "    try:\n",
    "        lines = response.strip().split(\"\\n\")\n",
    "        summary = lines[0].replace(\"Summary: \", \"\").strip()\n",
    "        score = lines[1].replace(\"Score: \", \"\").strip()\n",
    "        tone = lines[2].replace(\"Tone: \", \"\").strip()\n",
    "        return pd.Series([summary, score, tone])\n",
    "    except:\n",
    "        return pd.Series([\"\", \"\", \"\"])\n",
    "\n",
    "final_df[[\"summary\", \"score\", \"tone\"]] = final_df[\"analysis\"].apply(parse_analysis)\n",
    "final_df.to_csv(\"final_ai_crime_analysis.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b348cb-2318-4066-a85e-544fa8893fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>score</th>\n",
       "      <th>tone</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-Minute Daily AI News 2/22/2025</td>\n",
       "      <td>The post discusses recent developments in the ...</td>\n",
       "      <td></td>\n",
       "      <td>Score: +3 (Moderately impactful) - The post hi...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1iw2y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dawn of The New Age (Antichrist Unveiled)</td>\n",
       "      <td>The post discusses a fictional story about the...</td>\n",
       "      <td></td>\n",
       "      <td>Score: 2 (This post is not directly related to...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1ioaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-Minute Daily AI News 2/1/2025</td>\n",
       "      <td>This post discusses recent developments and in...</td>\n",
       "      <td></td>\n",
       "      <td>Score: 6 (Neutral)</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1ifq2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Teen victim of graphic deepfake pornography wo...</td>\n",
       "      <td>The post discusses a teen who was victimized b...</td>\n",
       "      <td></td>\n",
       "      <td>Score: +8 (Highly impactful) - This bill has t...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1hd0m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China Unveils Sci-Fi Inspired Spherical AI Pol...</td>\n",
       "      <td>The post discusses China unveiling a spherical...</td>\n",
       "      <td></td>\n",
       "      <td>Score: +7 (Highly impactful) - This developmen...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1hcg2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                 One-Minute Daily AI News 2/22/2025   \n",
       "1      The Dawn of The New Age (Antichrist Unveiled)   \n",
       "2                  One-Minute Daily AI News 2/1/2025   \n",
       "3  Teen victim of graphic deepfake pornography wo...   \n",
       "4  China Unveils Sci-Fi Inspired Spherical AI Pol...   \n",
       "\n",
       "                                             summary score  \\\n",
       "0  The post discusses recent developments in the ...         \n",
       "1  The post discusses a fictional story about the...         \n",
       "2  This post discusses recent developments and in...         \n",
       "3  The post discusses a teen who was victimized b...         \n",
       "4  The post discusses China unveiling a spherical...         \n",
       "\n",
       "                                                tone  \\\n",
       "0  Score: +3 (Moderately impactful) - The post hi...   \n",
       "1  Score: 2 (This post is not directly related to...   \n",
       "2                                 Score: 6 (Neutral)   \n",
       "3  Score: +8 (Highly impactful) - This bill has t...   \n",
       "4  Score: +7 (Highly impactful) - This developmen...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://reddit.com/r/artificial/comments/1iw2y...  \n",
       "1  https://reddit.com/r/artificial/comments/1ioaj...  \n",
       "2  https://reddit.com/r/artificial/comments/1ifq2...  \n",
       "3  https://reddit.com/r/artificial/comments/1hd0m...  \n",
       "4  https://reddit.com/r/artificial/comments/1hcg2...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat(results).reset_index(drop=True)\n",
    "\n",
    "def parse_analysis(response):\n",
    "    try:\n",
    "        lines = response.strip().split(\"\\n\")\n",
    "        summary = lines[0].replace(\"Summary: \", \"\").strip()\n",
    "        score = lines[1].replace(\"Score: \", \"\").strip()\n",
    "        tone = lines[2].replace(\"Tone: \", \"\").strip()\n",
    "        return pd.Series([summary, score, tone])\n",
    "    except:\n",
    "        return pd.Series([\"\", \"\", \"\"])\n",
    "\n",
    "final_df[[\"summary\", \"score\", \"tone\"]] = final_df[\"analysis\"].apply(parse_analysis)\n",
    "final_df.to_csv(\"final_ai_crime_analysis.csv\", index=False)\n",
    "final_df[[\"title\", \"summary\", \"score\", \"tone\", \"url\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc4149-32b3-4c90-a93f-73367435895b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
